{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:24:08.326271Z",
     "start_time": "2025-09-20T06:24:03.528907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "from BitcoinModeler import *\n"
   ],
   "id": "cf2749c033d3e5b0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Bitcoin Price Prediction\n",
    "\n",
    "This notebook trains simple linear models for BTC price horizons **H1** and **H7**, evaluates them on **Train/Validation/Test**, plots performance\n"
   ],
   "id": "34f8d0af60098451"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üß± Data & Splits\n",
    "\n",
    "We load preprocessed CSVs for both horizons:\n",
    "\n",
    "- **Train**: used to fit model parameters  \n",
    "- **Validation (val)**: used to choose models/hyperparameters (no peeking at Test)  \n",
    "- **Test**: used once at the end for an unbiased performance estimate\n",
    "\n",
    "\n"
   ],
   "id": "841f98fc57ef0415"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:24:08.563154Z",
     "start_time": "2025-09-20T06:24:08.368328Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 - Train: (1877, 71), Val: (402, 71), Test: (403, 71)\n",
      "H7 - Train: (1873, 71), Val: (401, 71), Test: (402, 71)\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "# Load h1 data\n",
    "h1_train = pd.read_csv('data/processed/h1_train.csv')\n",
    "h1_val = pd.read_csv('data/processed/h1_val.csv')\n",
    "h1_test = pd.read_csv('data/processed/h1_test.csv')\n",
    "\n",
    "# Load h7 data\n",
    "h7_train = pd.read_csv('data/processed/h7_train.csv')\n",
    "h7_val = pd.read_csv('data/processed/h7_val.csv')\n",
    "h7_test = pd.read_csv('data/processed/h7_test.csv')\n",
    "\n",
    "print(f\"H1 - Train: {h1_train.shape}, Val: {h1_val.shape}, Test: {h1_test.shape}\")\n",
    "print(f\"H7 - Train: {h7_train.shape}, Val: {h7_val.shape}, Test: {h7_test.shape}\")"
   ],
   "id": "cde21a9141610241"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:24:10.605201Z",
     "start_time": "2025-09-20T06:24:10.584454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bundle_h1=DataManager.prepare(h1_train, h1_val, h1_test, \"y_btc_close_t+1\",\"H1\")\n",
    "bundle_h7=DataManager.prepare(h7_train, h7_val, h7_test, \"y_btc_close_t+7\",\"H7\")"
   ],
   "id": "ec7fac34345d7ac5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Note: Features are **already z-score normalized using train-only stats** in `split.py` to avoid leakage.",
   "id": "3c30ea9841cd2025"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:45:08.652674Z",
     "start_time": "2025-09-20T06:45:08.648879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# optional if you want to compare scaled vs unscaled \n",
    "#scaler_h1_cls = ScalerManager()\n",
    "#bundle_h1_scaled = scaler_h1_cls.scale_bundle(bundle_h1)\n",
    "\n",
    "#scaler_h7_cls = ScalerManager()\n",
    "#bundle_h7_scaled = scaler_h7_cls.scale_bundle(bundle_h7)\n",
    "#print(\"Class-based DataBundle objects created (both raw and scaled variants).\")\n"
   ],
   "id": "93976a52dd6156d2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üöÄ Model Runs\n",
    "\n",
    "We fit all three models on **H1 (1-hour)** and **H7 (7-day)** horizons, then print per-split metrics.\n"
   ],
   "id": "2b25f604a390e468"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:37:42.638066Z",
     "start_time": "2025-09-20T06:37:40.830982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Run experiments\n",
    "runner_h1 = ExperimentRunner(bundle_h1, scaled=True)\n",
    "df_h1 = runner_h1.run()\n",
    "\n",
    "runner_h7 = ExperimentRunner(bundle_h7, scaled=True)\n",
    "df_h7 = runner_h7.run()\n",
    "\n",
    "#runner_h1s = ExperimentRunner(bundle_h1_scaled, scaled=True)\n",
    "#df_h1s = runner_h1s.run()\n",
    "\n",
    "#runner_h7s = ExperimentRunner(bundle_h7_scaled, scaled=True)\n",
    "#df_h7s = runner_h7s.run()\n",
    "\n"
   ],
   "id": "fc0ee4efd6bfbd48",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zorad\\anaconda3\\envs\\Final\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.435e+05, tolerance: 9.959e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üìä Results Table (All Models √ó Splits)\n",
   "id": "621c168a9f336429"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:37:34.803153Z",
     "start_time": "2025-09-20T06:37:34.793496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Merge all for a single summary table \n",
    "results_df_classes = pd.concat([df_h1, df_h7], ignore_index=True)\n",
    "print(\"\\n‚Äî‚Äî‚Äî CLASS-BASED RESULTS SUMMARY ‚Äî‚Äî‚Äî\")\n",
    "print(results_df_classes.to_string(index=False, float_format=\"%.6f\"))"
   ],
   "id": "c6d7b5252d6d7ea6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Äî‚Äî‚Äî CLASS-BASED RESULTS SUMMARY ‚Äî‚Äî‚Äî\n",
      "Horizon Scaled?  Model    Dataset            MSE        RMSE        MAE       R2\n",
      "     H1     Yes Linear Validation     386.460641   19.658602  12.094807 0.983038\n",
      "     H1     Yes Linear       Test  235784.524346  485.576487 245.162722 0.988930\n",
      "     H1     Yes  Ridge Validation     560.397341   23.672713  15.585227 0.975404\n",
      "     H1     Yes  Ridge       Test  301181.604841  548.800150 281.239009 0.985860\n",
      "     H1     Yes  Lasso Validation     375.775904   19.384940  11.561632 0.983507\n",
      "     H1     Yes  Lasso       Test  214931.363047  463.606906 235.702833 0.989909\n",
      "     H7     Yes Linear Validation    3065.284967   55.365016  35.400979 0.865957\n",
      "     H7     Yes Linear       Test 2184313.997933 1477.942488 799.256720 0.897488\n",
      "     H7     Yes  Ridge Validation    3161.001753   56.222787  35.163971 0.861772\n",
      "     H7     Yes  Ridge       Test 2158626.102192 1469.226362 783.045097 0.898694\n",
      "     H7     Yes  Lasso Validation    3031.758813   55.061409  35.240464 0.867423\n",
      "     H7     Yes  Lasso       Test 2158126.899578 1469.056466 794.051014 0.898717\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:40:54.002754Z",
     "start_time": "2025-09-20T06:40:53.998939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Feature importance for Lasso models\n",
    "\n",
    "lasso_h1 = [m for m in runner_h1.models if m.name == \"Lasso\"][0]\n",
    "lasso_h7 = [m for m in runner_h7.models if m.name == \"Lasso\"][0]\n",
    "H1ModelWrap=ModelWrapper(\"H1\",lasso_h1.model)\n",
    "H7ModelWrap=ModelWrapper(\"H7\",lasso_h7.model)\n",
    "\n"
   ],
   "id": "12d6b216a32746b7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìà Lasso Performance ‚Äî Validation vs Test\n",
    "\n",
    "The chart below compares **Nonzero** vs **Zero**  for each horizon (H1, H7).  \n",
    "\n"
   ],
   "id": "9cf8ed1694c7d482"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Feature Importance Analysis\")\n",
    "print(\"=\"*50)\n",
    "# H1 Lasso\n",
    "h1_lasso_features = H1ModelWrap.plot_feature_importance(bundle_h1.feature_cols, 'H1 Lasso Regression')\n",
    "# H7 Lasso  \n",
    "h7_lasso_features = H7ModelWrap.plot_feature_importance(bundle_h7.feature_cols, 'H7 Lasso Regression')"
   ],
   "id": "8bb23903dac14057"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üèÜ Best Model Summary (Chosen by Validation RMSE)\n",
    "\n",
    "For **each horizon**, we pick the model  with the **lowest Validation RMSE**, then report its **R2** and **Test_MSE** metrics.  \n",
    "\n"
   ],
   "id": "b30de68fc5a73de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:44:03.860499Z",
     "start_time": "2025-09-20T06:44:03.840425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -- Produce and print the best-model summary (pick by Validation RMSE; show Test metrics)\n",
    "best_summary = ModelWrapper.best_summary(results_df_classes, metric=\"RMSE\", prefer_scaled=None)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL SUMMARY ‚Äî picked by lowest Validation RMSE; Test metrics shown\")\n",
    "print(\"=\"*80)\n",
    "print(best_summary.to_string(index=False, float_format=\"%.6f\"))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL SUMMARY ‚Äî picked by lowest Validation R2; Test metrics shown\")\n",
    "print(\"=\"*80)\n",
    "best_summaryR2 = ModelWrapper.best_summary(results_df_classes, metric=\"R2\", prefer_scaled=None)\n",
    "print(best_summaryR2.to_string(index=False, float_format=\"%.6f\"))\n",
    "\n",
    "H1LassoNonZeroCoef=H1ModelWrap.get_lasso_nonzero_coef(bundle_h1.feature_cols)\n",
    "H7LassoNonZeroCoef=H7ModelWrap.get_lasso_nonzero_coef(bundle_h1.feature_cols)\n",
    "result = (\n",
    "    f\"H1: {H1LassoNonZeroCoef}/{len(bundle_h1.feature_cols)} features selected | \"\n",
    "    f\"H7: {H7LassoNonZeroCoef}/{len(bundle_h7.feature_cols)} features selected\"\n",
    ")\n",
    "print(result)\n",
    "\n"
   ],
   "id": "fea0d92f16a6fbef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BEST MODEL SUMMARY ‚Äî picked by lowest Validation RMSE; Test metrics shown\n",
      "================================================================================\n",
      "Horizon Model Scaled?  Val_RMSE            MSE        RMSE        MAE       R2\n",
      "     H1 Lasso     Yes 19.384940  214931.363047  463.606906 235.702833 0.989909\n",
      "     H7 Lasso     Yes 55.061409 2158126.899578 1469.056466 794.051014 0.898717\n",
      "\n",
      "================================================================================\n",
      "BEST MODEL SUMMARY ‚Äî picked by lowest Validation R2; Test metrics shown\n",
      "================================================================================\n",
      "Horizon Model Scaled?   Val_R2            MSE        RMSE        MAE       R2\n",
      "     H1 Lasso     Yes 0.983507  214931.363047  463.606906 235.702833 0.989909\n",
      "     H7 Lasso     Yes 0.867423 2158126.899578 1469.056466 794.051014 0.898717\n",
      "\n",
      "Lasso Regression Feature Selection:\n",
      "\n",
      "Lasso Regression Feature Selection:\n",
      "H1: 53/69 features selected | H7: 62/69 features selected\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üß≠ Baselines & Diagnostics \n",
    "  1. Compare model performance across different prediction timeframes\n",
    "  2. Regularization effects of Ridge vs Lasso regression\n",
    "  3. Feature selection capabilities of Lasso regression\n",
    "  4. Model stability across validation and test sets\n"
   ],
   "id": "dedab4656bd044ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "74e7a13204aaf6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T06:24:16.672698Z",
     "start_time": "2025-09-20T06:24:16.666437Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d617e2eed6ca3ad5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
